{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import arviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "timescales = [5, 14, 28],\n",
    "weights  = None,\n",
    "test_cutoff = None,\n",
    "\n",
    "political_families = [\n",
    "        \"farleft\",\n",
    "        \"left\",\n",
    "        \"green\",\n",
    "        \"center\",\n",
    "        \"right\",\n",
    "        \"farright\",\n",
    "        \"souverainistes\",\n",
    "        \"other\",\n",
    "    ]\n",
    "\n",
    "gp_config = {\n",
    "            \"lengthscale\": timescales,\n",
    "            \"kernel\": \"gaussian\",\n",
    "            \"zerosum\": True,\n",
    "            \"variance_limit\": 0.95,\n",
    "            \"variance_weight\": weights,\n",
    "        }\n",
    "\n",
    "\n",
    "def dates_to_idx(timelist, reference_date):\n",
    "    \"\"\"Convert datetimes to numbers in reference to reference_date\"\"\"\n",
    "    t = (reference_date - timelist) / np.timedelta64(1, \"D\")\n",
    "    return np.asarray(t)\n",
    "\n",
    "\n",
    "def standardize(series):\n",
    "    \"\"\"Standardize a pandas series\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def _load_old_polls() -> pd.DataFrame:\n",
    "    polls = pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/pollsposition/data/main/sondages\"\n",
    "        \"/tour1_complet_unitedfl.csv\",\n",
    "        index_col=0,\n",
    "        parse_dates=[\"dateelection\", \"date\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    # only president elections after 2002\n",
    "    polls = polls[(polls.date >= \"2002-01\") & (polls.type == \"president\")].drop(\n",
    "        [\n",
    "            \"type\",\n",
    "            \"abstention\",\n",
    "            \"undecided\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # no green party candidate in 2017\n",
    "    polls.loc[polls[\"dateelection\"] == \"2017-04-23\", \"nbgreen\"] = 0\n",
    "    polls[\"date\"] = polls[\"date\"].dt.date\n",
    "\n",
    "    return polls.sort_values(\n",
    "        [\"dateelection\", \"date\", \"sondage\", \"samplesize\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "def _load_2022_polls() -> pd.DataFrame:\n",
    "    url = \"https://raw.githubusercontent.com/pollsposition/data/main/sondages/presidentielles_2022.json\"\n",
    "    response = urlopen(url)\n",
    "    raw_polls = json.loads(response.read())\n",
    "    new_polls = _clean_up_json(raw_polls)\n",
    "    return _format_2022_polls(new_polls)\n",
    "\n",
    "def _load_polls() -> pd.DataFrame:\n",
    "        old_polls = _load_old_polls()\n",
    "        new_polls = _load_2022_polls()\n",
    "\n",
    "        polls = (\n",
    "            pd.concat([old_polls, new_polls], axis=0)\n",
    "            .sort_values([\"dateelection\", \"date\", \"sondage\", \"samplesize\"])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        polls[\"nbsouverainistes\"] = polls[\"nbsouverainistes\"].fillna(0)\n",
    "        polls[\"date\"] = pd.to_datetime(polls[\"date\"])\n",
    "\n",
    "        # add empty line for 2022 results\n",
    "        polls = polls.set_index(\"date\")\n",
    "        date = pd.to_datetime(\"2022-04-10\")\n",
    "\n",
    "\n",
    "        polls.loc[date] = np.NaN\n",
    "        polls.loc[date, \"dateelection\"] = pd.to_datetime(\"2022-04-10\")\n",
    "        polls.loc[date, \"sondage\"] = \"result\"\n",
    "\n",
    "        return polls.reset_index()\n",
    "\n",
    "def _clean_up_json(raw_polls: pd.DataFrame) -> pd.DataFrame:\n",
    "        metadata = [\n",
    "            pd.json_normalize(raw_polls[\"sondages\"][poll])[\n",
    "                [\"institut\", \"date_debut\", \"date_fin\", \"premier_tour\"]\n",
    "            ]\n",
    "            for poll in raw_polls[\"sondages\"].keys()\n",
    "        ]\n",
    "        metadata = pd.concat(metadata).sort_values(\"date_debut\")\n",
    "        metadata[[\"date_debut\", \"date_fin\"]] = metadata[\n",
    "            [\"date_debut\", \"date_fin\"]\n",
    "        ].apply(pd.to_datetime)\n",
    "        metadata = metadata[metadata.date_debut >= \"2022-01-01\"].reset_index(drop=True)\n",
    "\n",
    "        polls_temp = []\n",
    "        for _, row in metadata.iterrows():\n",
    "            poll = row[\"premier_tour\"]\n",
    "            polls_temp.append(select_hypothesis(poll))\n",
    "        polls_temp = pd.concat(polls_temp).reset_index(drop=True)\n",
    "\n",
    "        # exclude certitude\n",
    "        new_polls = pd.concat([metadata, polls_temp], axis=1).drop(\n",
    "            [\"premier_tour\", \"base\", \"nspp\", \"hypothese\"], axis=1\n",
    "        )\n",
    "        return new_polls.drop(new_polls.filter(regex=\"certitude.\").columns, axis=1)\n",
    "\n",
    "def _format_2022_polls(new_polls: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        # different renames\n",
    "        to_rename = new_polls.filter(regex=\"intentions\\.\").columns\n",
    "        new_names = (\n",
    "            new_polls.filter(regex=\"intentions\\.\")\n",
    "            .columns.str.split(\".\", expand=True)\n",
    "            .droplevel(0)\n",
    "        )\n",
    "        AFFILIATIONS = {\n",
    "            \"Jean-Luc Mélenchon\": \"nbfarleft\",\n",
    "            \"Anne Hidalgo\": \"nbleft\",\n",
    "            \"Yannick Jadot\": \"nbgreen\",\n",
    "            \"Emmanuel Macron\": \"nbcenter\",\n",
    "            \"Valérie Pécresse\": \"nbright\",\n",
    "            \"Marine Le Pen\": \"nbfarright\",\n",
    "            \"Éric Zemmour\": \"nbsouverainistes\",\n",
    "        }\n",
    "\n",
    "        new_polls = (\n",
    "            new_polls.rename(\n",
    "                columns=(\n",
    "                    {\"institut\": \"sondage\", \"intentions_exprimees\": \"samplesize\"}\n",
    "                    | dict(zip(to_rename, new_names))\n",
    "                )\n",
    "            )\n",
    "            .rename(columns=AFFILIATIONS)\n",
    "            .replace({\"Harris interactive\": \"Harris\", \"Opinionway\": \"OpinionWay\"})\n",
    "        )\n",
    "\n",
    "        # compute median date\n",
    "        new_polls[\"date\"] = pd.to_datetime(\n",
    "            np.median(\n",
    "                new_polls[[\"date_debut\", \"date_fin\"]].values.astype(np.int64), axis=1\n",
    "            )\n",
    "        )\n",
    "        new_polls[\"date\"] = new_polls[\"date\"].dt.date\n",
    "        new_polls[\"dateelection\"] = pd.to_datetime(\"2022-04-10\")\n",
    "        new_polls = new_polls.drop([\"date_debut\", \"date_fin\"], axis=1)\n",
    "\n",
    "        # aggregate other parties:\n",
    "        core_cols = [\"sondage\", \"date\", \"dateelection\", \"samplesize\"] + list(\n",
    "            AFFILIATIONS.values()\n",
    "        )\n",
    "        rest = new_polls[new_polls.columns.difference(core_cols)]\n",
    "        new_polls[\"nbother\"] = rest.sum(axis=1)\n",
    "\n",
    "        return new_polls.drop(rest.columns, axis=1)\n",
    "\n",
    "def _clean_polls(\n",
    "        polls: pd.DataFrame,\n",
    "        test_cutoff: pd.Timedelta = None,\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "        results_raw, results_mult, polls = _format_polls(\n",
    "            polls, political_families\n",
    "        )\n",
    "        (\n",
    "            polls_train,\n",
    "            polls_test,\n",
    "        ) = _train_split(polls, test_cutoff=test_cutoff)\n",
    "\n",
    "        return polls_train, polls_test, results_raw, results_mult\n",
    "\n",
    "def _format_polls(\n",
    "         polls: pd.DataFrame, parties_complete: List[str]\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        # start all elections on Jan 1st\n",
    "        dfs = []\n",
    "        for date in polls.dateelection.unique():\n",
    "            date = pd.to_datetime(date)\n",
    "            df = polls[(polls.dateelection == date) & (polls.date >= f\"{date.year}-01\")]\n",
    "            df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n",
    "            dfs.append(df)\n",
    "\n",
    "        # compute \"other\" category\n",
    "        polls = (\n",
    "            pd.concat(dfs)\n",
    "            .set_index([\"dateelection\", \"date\", \"countdown\", \"sondage\", \"samplesize\"])\n",
    "            .rename(\n",
    "                columns={\n",
    "                    col: col.split(\"nb\")[1] for col in polls if col.startswith(\"nb\")\n",
    "                }\n",
    "            )[parties_complete[:-1]]\n",
    "        )\n",
    "        polls[\"other\"] = 100 - polls.sum(1)\n",
    "        np.testing.assert_allclose(polls.sum(1).values, 100)\n",
    "\n",
    "        # isolate results\n",
    "        polls = polls.reset_index()\n",
    "        results_raw = polls[polls.sondage == \"result\"]\n",
    "        polls = polls[polls.sondage != \"result\"].set_index([\"date\", \"sondage\"])\n",
    "\n",
    "        # cast polls as multinomial obs\n",
    "        polls = cast_as_multinomial(polls)\n",
    "\n",
    "        # cast results as multinomial\n",
    "        results_mult = results_as_multinomial(results_raw)\n",
    "\n",
    "        return results_raw, results_mult, polls.reset_index()\n",
    "\n",
    "def select_hypothesis(poll: List) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Select hypothesis with Taubira when present.\n",
    "        Just return poll otherwise.\n",
    "        \"\"\"\n",
    "        for hypothesis in poll:\n",
    "            intentions = hypothesis[\"intentions\"]\n",
    "            if \"Christiane Taubira\" in intentions.keys():\n",
    "                # this return assumes there is only one Taubira hypothesis\n",
    "                return pd.json_normalize(hypothesis)\n",
    "        return pd.json_normalize(hypothesis)\n",
    "\n",
    "def _train_split(\n",
    "    polls: pd.DataFrame, test_cutoff: pd.Timedelta = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    last_election = polls.dateelection.unique()[-1]\n",
    "    polls_train = polls[polls.dateelection != last_election]\n",
    "    polls_test = polls[polls.dateelection == last_election]\n",
    "\n",
    "    if test_cutoff:\n",
    "        test_cutoff_ = last_election - test_cutoff\n",
    "    else:\n",
    "        test_cutoff_ = last_election - pd.Timedelta(5, \"D\")\n",
    "\n",
    "    polls_train = pd.concat(\n",
    "        [polls_train, polls_test[polls_test.date <= test_cutoff_]]\n",
    "    )\n",
    "    polls_test = polls_test[polls_test.date > test_cutoff_]\n",
    "\n",
    "    return polls_train, polls_test\n",
    "\n",
    "def cast_as_multinomial(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df[political_families] = (\n",
    "            (df[political_families] / 100)\n",
    "            .mul(df[\"samplesize\"], axis=0)\n",
    "            .round()\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "        df[\"samplesize\"] = df[political_families].sum(1)\n",
    "\n",
    "        return df\n",
    "\n",
    "def results_as_multinomial(results_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "        # need number of people who voted\n",
    "        raw_json = pd.read_json(\n",
    "            \"https://raw.githubusercontent.com/pollsposition/data/main/resultats/presidentielles\"\n",
    "            \".json\",\n",
    "        )\n",
    "        raw_json = raw_json.loc[\"premier_tour\"].to_dict()\n",
    "\n",
    "        jsons = []\n",
    "        for year, dateelection in zip(\n",
    "            results_raw.dateelection.dt.year.unique(), results_raw.dateelection.unique()\n",
    "        ):\n",
    "            try:\n",
    "                df = pd.json_normalize(raw_json[year])[[\"exprimes\"]]\n",
    "                df[\"dateelection\"] = dateelection\n",
    "                jsons.append(df)\n",
    "            # 2022 results not available yet\n",
    "            except KeyError:\n",
    "                continue\n",
    "        jsons = pd.concat(jsons)\n",
    "\n",
    "        results_mult = (\n",
    "            results_raw.join(jsons.set_index(\"dateelection\"), on=\"dateelection\")\n",
    "            .drop(\"samplesize\", axis=\"columns\")\n",
    "            .rename(columns={\"exprimes\": \"samplesize\"})\n",
    "        )\n",
    "        results_mult[\"samplesize\"] = (\n",
    "            results_mult[\"samplesize\"] // 100\n",
    "        )  # to prevent overflow in Multinomial\n",
    "\n",
    "        return cast_as_multinomial(results_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16373/1914824913.py:95: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  polls.loc[date] = np.NaN\n",
      "/tmp/ipykernel_16373/1914824913.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n",
      "/tmp/ipykernel_16373/1914824913.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n",
      "/tmp/ipykernel_16373/1914824913.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n",
      "/tmp/ipykernel_16373/1914824913.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n",
      "/tmp/ipykernel_16373/1914824913.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"countdown\"] = dates_to_idx(df[\"date\"], reference_date=date).astype(int)\n"
     ]
    }
   ],
   "source": [
    "polls = _load_polls()\n",
    "\n",
    "(\n",
    "    polls_train,\n",
    "    polls_test,\n",
    "    results_raw,\n",
    "    results_mult,\n",
    ") = _clean_polls(polls, test_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpapproximation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_gp_basis\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mzerosumnormal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZeroSumNormal\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc3'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class PresidentialElectionsModel:\n",
    "    \"\"\"A model for the French 2022 presidential elections.\n",
    "\n",
    "    Poll and election results are modeled using a Dirichlet Multinomial\n",
    "    regression. We build upon the idea in [1,2]_ to use a backwards random walk\n",
    "    to link the prediction for the election results and the observed poll\n",
    "    results. The dependence between the succesive values of the latent\n",
    "    popularity is modeled using a multivariate gaussian process with a diagonal\n",
    "    covariance metic.\n",
    "\n",
    "    We pool information from past elections by assigning candidates to a set of\n",
    "    political families and putting a hierarchical model over these families.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1]: Linzer, Drew A. “Dynamic Bayesian Forecasting of Presidential Elections in the States.”\n",
    "            Journal of the American Statistical Association 108, no. 501 (2013): 124–134.\n",
    "    .. [2]: Stoetzer, Lukas F., Marcel Neunhoeffer, Thomas Gschwend, Simon Munzert, and Sebastian Sternberg.\n",
    "            “Forecasting Elections in Multiparty Systems: A Bayesian Approach Combining Polls and Fundamentals.”\n",
    "            Political Analysis 27, no. 2 (2019): 255–262.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        election_date: str,\n",
    "        timescales: List[int] = [5, 14, 28],\n",
    "        weights: List[float] = None,\n",
    "        test_cutoff: pd.Timedelta = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the model builder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        election_date\n",
    "            Date of the election whose result we want to predict.\n",
    "        timescales\n",
    "            The typical number of days over which the opinion is assumed to\n",
    "            move. We usually use several Gaussian Processes that each correspond\n",
    "            to a different timescale (in days).\n",
    "        weights\n",
    "            The weight to give to each timescale. Defaults to each timescale\n",
    "            having the same weight.\n",
    "        test_cutoff\n",
    "            How much of the dataset for ``election_to_predict`` we want to cut to test the model.\n",
    "            If 2 months for instance, the last two months of polls in the campaign won't be fed to\n",
    "            the model.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        polls = self._load_polls()\n",
    "        (\n",
    "            self.polls_train,\n",
    "            self.polls_test,\n",
    "            self.results_raw,\n",
    "            self.results_mult,\n",
    "        ) = self._clean_polls(polls, test_cutoff)\n",
    "\n",
    "        _, self.unique_elections = self.polls_train[\"dateelection\"].factorize()\n",
    "        _, self.unique_pollsters = self.polls_train[\"sondage\"].factorize()\n",
    "        self.results_oos = self.results_mult[\n",
    "            self.results_mult.dateelection != election_date\n",
    "        ].copy()\n",
    "\n",
    "        self._load_predictors()\n",
    "        (\n",
    "            self.results_preds,\n",
    "            self.campaign_preds,\n",
    "        ) = self._standardize_continuous_predictors()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _load_predictors(self):\n",
    "        self.unemployment_data = self._load_generic_predictor(\n",
    "            \"https://raw.githubusercontent.com/pollsposition/data/main/predicteurs\"\n",
    "            \"/chomage_national_trim.csv\",\n",
    "            name=\"unemployment\",\n",
    "            freq=\"Q\",\n",
    "            skiprows=2,\n",
    "        )\n",
    "        self.polls_train, self.polls_test, self.results_mult = self._merge_with_data(\n",
    "            self.unemployment_data, freq=\"Q\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def _merge_with_data(\n",
    "        self, predictor: pd.DataFrame, freq: str\n",
    "    ) -> List[pd.DataFrame]:\n",
    "        polls_train = self.polls_train.copy()\n",
    "        polls_test = self.polls_test.copy()\n",
    "        results_mult = self.results_mult.copy()\n",
    "        dfs = []\n",
    "\n",
    "        for data in [polls_train, polls_test, results_mult]:\n",
    "            # add freq to data\n",
    "            data.index = data[\"date\"].dt.to_period(freq)\n",
    "            # merge with data\n",
    "            dfs.append(data.join(predictor).reset_index(drop=True))\n",
    "\n",
    "        return dfs\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_generic_predictor(\n",
    "        file: str, name: str, freq: str, skiprows: int, sep: str = \";\"\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        data = pd.read_csv(\n",
    "            file,\n",
    "            sep=sep,\n",
    "            skiprows=skiprows,\n",
    "        ).iloc[:, [0, 1]]\n",
    "        data.columns = [\"date\", name]\n",
    "        data = data.sort_values(\"date\")\n",
    "\n",
    "        # as timestamps variables:\n",
    "        data.index = pd.period_range(\n",
    "            start=data.date.iloc[0], periods=len(data), freq=freq\n",
    "        )\n",
    "\n",
    "        return data.drop(\"date\", axis=1)\n",
    "\n",
    "    def _standardize_continuous_predictors(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Substract mean and divide by std to help with sampling and setting priors.\"\"\"\n",
    "        continuous_predictors = [\n",
    "            \"unemployment\",\n",
    "        ]\n",
    "        self.continuous_predictors = (\n",
    "            pd.concat(\n",
    "                [\n",
    "                    self.polls_train[[\"date\"] + continuous_predictors],\n",
    "                    self.results_mult[[\"date\"] + continuous_predictors],\n",
    "                ]\n",
    "            )\n",
    "            .set_index(\"date\")\n",
    "            .sort_index()\n",
    "        )\n",
    "        cont_preds_stdz = standardize(self.continuous_predictors)\n",
    "\n",
    "        return (\n",
    "            cont_preds_stdz.loc[self.unique_elections],\n",
    "            cont_preds_stdz.loc[\n",
    "                self.continuous_predictors.index.difference(self.unique_elections)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def build_model(\n",
    "        self,\n",
    "        polls: pd.DataFrame = None,\n",
    "        continuous_predictors: pd.DataFrame = None,\n",
    "    ) -> pm.Model:\n",
    "        \"\"\"Build and return a pymc3 model for the poll results and fundamental data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        polls\n",
    "            Poll results from past and current elections. This only needs to be\n",
    "            specified for out-of-sample predictions to run the model on another\n",
    "            dataset than the training data.\n",
    "        continuous_predictors\n",
    "            Continuous predictors, or fundamentals. This only need to be\n",
    "            specified for out-of-sample predictions to run the model on another\n",
    "            dataset than the training data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A PyMC model in the form of a pymc.Model() instance.\n",
    "\n",
    "        \"\"\"\n",
    "        (\n",
    "            self.pollster_id,\n",
    "            self.countdown_id,\n",
    "            self.election_id,\n",
    "            self.coords,\n",
    "        ) = self._build_coords(polls)\n",
    "\n",
    "        with pm.Model(coords=self.coords) as model:\n",
    "\n",
    "            data_containers, non_competing_parties = self._build_data_containers(\n",
    "                polls, continuous_predictors\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #                   BASELINE COMPONENTS\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            # Baseline latent popularity for each political family. Shared\n",
    "            # across elections.\n",
    "            party_baseline_sd = pm.HalfNormal(\"party_baseline_sd\", 0.5)\n",
    "            party_baseline = ZeroSumNormal(\n",
    "                \"party_baseline\", sigma=party_baseline_sd, dims=\"parties_complete\"\n",
    "            )\n",
    "\n",
    "            # Election-specific deviation from baseline of the latent popularity\n",
    "            # of each political family.\n",
    "            lsd_baseline = pm.Normal(\"election_party_baseline_sd_baseline\", sigma=0.5)\n",
    "            lsd_party_effect = ZeroSumNormal(\n",
    "                \"election_party_baseline_sd_party_effect\",\n",
    "                sigma=0.5,\n",
    "                dims=\"parties_complete\",\n",
    "            )\n",
    "            election_party_baseline_sd = pm.Deterministic(\n",
    "                \"election_party_baseline_sd\",\n",
    "                aet.exp(lsd_baseline + lsd_party_effect),\n",
    "                dims=\"parties_complete\",\n",
    "            )\n",
    "            election_party_baseline = (\n",
    "                ZeroSumNormal(  # as a GP over elections to account for order?\n",
    "                    \"election_party_baseline\",\n",
    "                    sigma=election_party_baseline_sd[None, :],\n",
    "                    dims=(\"elections\", \"parties_complete\"),\n",
    "                    zerosum_axes=(0, 1),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #                        HOUSE EFFECTS\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            # Baseline for polls' bias towards the different political families.\n",
    "            # These biases are shared by pollsters, i.e. they can be interpreted\n",
    "            # as the market's bias.\n",
    "            poll_bias = (\n",
    "                ZeroSumNormal(  # equivalent to no ZeroSum on pollsters in house_effects\n",
    "                    \"poll_bias\",\n",
    "                    sigma=0.15,\n",
    "                    dims=\"parties_complete\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Baseline for house effect (per political family)\n",
    "            house_effects = ZeroSumNormal(\n",
    "                \"house_effects\",\n",
    "                sigma=0.15,\n",
    "                dims=(\"pollsters\", \"parties_complete\"),\n",
    "                zerosum_axes=(0, 1),\n",
    "            )\n",
    "\n",
    "            # Election-specific house effect (per political family)\n",
    "            house_election_effects_sd = pm.HalfNormal(\n",
    "                \"house_election_effects_sd\",\n",
    "                0.15,\n",
    "                dims=(\"pollsters\", \"parties_complete\"),\n",
    "            )\n",
    "            house_election_effects_raw = ZeroSumNormal(\n",
    "                \"house_election_effects_raw\",\n",
    "                dims=(\"pollsters\", \"parties_complete\", \"elections\"),\n",
    "                zerosum_axes=(0, 1, 2),\n",
    "            )\n",
    "            house_election_effects = pm.Deterministic(\n",
    "                \"house_election_effects\",\n",
    "                house_election_effects_sd[..., None] * house_election_effects_raw,\n",
    "                dims=(\"pollsters\", \"parties_complete\", \"elections\"),\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #                  FUNDAMENTAL COMPONENT\n",
    "            #\n",
    "            # It is commonly assumed that the results of the elections\n",
    "            # are mostly determined by economic fundamentals, and\n",
    "            # that the opinion \"drifts\" towards this result during the\n",
    "            # campaign, so to speak.\n",
    "            #\n",
    "            # The coefficient below accounts for the effect of the\n",
    "            # unemployment on the election result.\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            unemployment_effect = ZeroSumNormal(\n",
    "                \"unemployment_effect\",\n",
    "                sigma=0.15,\n",
    "                dims=\"parties_complete\",\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #               TIME-VARYING COMPONENT\n",
    "            #\n",
    "            # The latent popularity of political families varies over\n",
    "            # the course of an election. We model this evolution with\n",
    "            # gaussian processes.\n",
    "            #\n",
    "            # We currently use gaussian processes with 3 different\n",
    "            # lengthscales to account for the typical timescales over which\n",
    "            # opinion can change.\n",
    "            #\n",
    "            # The time evolution has two components: one that is common to all\n",
    "            # elections (the baseline), and another one for each election,\n",
    "            # which is a deviation from the common baseline.\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            # Build the gaussian process basis functions\n",
    "            gp_basis_funcs, gp_basis_dim = make_gp_basis(\n",
    "                time=self.coords[\"countdown\"], gp_config=self.gp_config, key=\"parties\"\n",
    "            )\n",
    "\n",
    "            # Baseline (shared across elections) for the time-varying component\n",
    "            # of the latent popularity.\n",
    "            # --------------------------------------------------------\n",
    "            lsd_baseline = pm.Normal(\"lsd_baseline\", sigma=0.3)\n",
    "            lsd_party_effect = ZeroSumNormal(\n",
    "                \"lsd_party_effect_party_amplitude\", sigma=0.2, dims=\"parties_complete\"\n",
    "            )\n",
    "            party_time_weight = pm.Deterministic(\n",
    "                \"party_time_weight\",\n",
    "                aet.exp(lsd_baseline + lsd_party_effect),\n",
    "                dims=\"parties_complete\",\n",
    "            )\n",
    "\n",
    "            party_time_coefs_raw = ZeroSumNormal(\n",
    "                \"party_time_coefs_raw\",\n",
    "                sigma=1,\n",
    "                dims=(gp_basis_dim, \"parties_complete\"),\n",
    "                zerosum_axes=-1,\n",
    "            )\n",
    "            party_time_effect = pm.Deterministic(\n",
    "                \"party_time_effect\",\n",
    "                aet.tensordot(\n",
    "                    gp_basis_funcs,\n",
    "                    party_time_weight[None, ...] * party_time_coefs_raw,\n",
    "                    axes=(1, 0),\n",
    "                ),\n",
    "                dims=(\"countdown\", \"parties_complete\"),\n",
    "            )\n",
    "\n",
    "            # Election-specific time-varying component of the latent popularity\n",
    "            # --------------------------------------------------------\n",
    "            lsd_party_effect = ZeroSumNormal(\n",
    "                \"lsd_party_effect_election_party_amplitude\",\n",
    "                sigma=0.2,\n",
    "                dims=\"parties_complete\",\n",
    "            )\n",
    "            lsd_election_effect = ZeroSumNormal(\n",
    "                \"lsd_election_effect\", sigma=0.2, dims=\"elections\"\n",
    "            )\n",
    "            lsd_election_party_sd = pm.HalfNormal(\"lsd_election_party_sd\", 0.2)\n",
    "            lsd_election_party_raw = ZeroSumNormal(\n",
    "                \"lsd_election_party_raw\",\n",
    "                dims=(\"parties_complete\", \"elections\"),\n",
    "                zerosum_axes=(0, 1),\n",
    "            )\n",
    "            lsd_election_party_effect = pm.Deterministic(\n",
    "                \"lsd_election_party_effect\",\n",
    "                lsd_election_party_sd * lsd_election_party_raw,\n",
    "                dims=(\"parties_complete\", \"elections\"),\n",
    "            )\n",
    "            election_party_time_weight = pm.Deterministic(\n",
    "                \"election_party_time_weight\",\n",
    "                aet.exp(\n",
    "                    lsd_party_effect[:, None]\n",
    "                    + lsd_election_effect[None, :]\n",
    "                    + lsd_election_party_effect\n",
    "                ),\n",
    "                dims=(\"parties_complete\", \"elections\"),\n",
    "            )\n",
    "\n",
    "            election_party_time_coefs = ZeroSumNormal(\n",
    "                \"election_party_time_coefs\",\n",
    "                sigma=election_party_time_weight[None, ...],\n",
    "                dims=(gp_basis_dim, \"parties_complete\", \"elections\"),\n",
    "                zerosum_axes=(1, 2),\n",
    "            )\n",
    "            election_party_time_effect = pm.Deterministic(\n",
    "                \"election_party_time_effect\",\n",
    "                aet.tensordot(\n",
    "                    gp_basis_funcs,\n",
    "                    election_party_time_coefs,\n",
    "                    axes=(1, 0),\n",
    "                ),\n",
    "                dims=(\"countdown\", \"parties_complete\", \"elections\"),\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #                      POLL RESULTS\n",
    "            #\n",
    "            # In this section we use the variables defined before to\n",
    "            # model the latent popularity of political families and how\n",
    "            # this popularity translates into poll results.\n",
    "            #\n",
    "            # This part of the model is used to inform predictions about\n",
    "            # the outcomes with the current state of polling; this is the\n",
    "            # only place where poll results enter the model.\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            latent_mu = (\n",
    "                party_baseline\n",
    "                + election_party_baseline[data_containers[\"election_idx\"]]\n",
    "                + party_time_effect[data_containers[\"countdown_idx\"]]\n",
    "                + election_party_time_effect[\n",
    "                    data_containers[\"countdown_idx\"], :, data_containers[\"election_idx\"]\n",
    "                ]\n",
    "                + aet.dot(\n",
    "                    data_containers[\"stdz_unemp\"][:, None], unemployment_effect[None, :]\n",
    "                )\n",
    "            )\n",
    "            latent_mu = latent_mu + non_competing_parties[\"polls_additive\"]\n",
    "            pm.Deterministic(\n",
    "                \"latent_popularity\",\n",
    "                aet.nnet.softmax(latent_mu),\n",
    "                dims=(\"observations\", \"parties_complete\"),\n",
    "            )\n",
    "            noisy_mu = (\n",
    "                latent_mu\n",
    "                + poll_bias[None, :]  # let bias vary during election period?\n",
    "                + house_effects[data_containers[\"pollster_idx\"]]\n",
    "                + house_election_effects[\n",
    "                    data_containers[\"pollster_idx\"], :, data_containers[\"election_idx\"]\n",
    "                ]\n",
    "                * non_competing_parties[\"polls_multiplicative\"]\n",
    "            )\n",
    "\n",
    "            noisy_popularity = pm.Deterministic(\n",
    "                \"noisy_popularity\",\n",
    "                aet.nnet.softmax(noisy_mu),\n",
    "                dims=(\"observations\", \"parties_complete\"),\n",
    "            )\n",
    "\n",
    "            # The concentration parameter of a Dirichlet-Multinomial distribution\n",
    "            # can be interpreted as the effective number of trials.\n",
    "            #\n",
    "            # The mean (1000) is thus taken to be roughly the sample size of\n",
    "            # polls, and the standard deviation accounts for the variation in\n",
    "            # sample size.\n",
    "            concentration_polls = pm.InverseGamma(\n",
    "                \"concentration_polls\", mu=1000, sigma=200\n",
    "            )\n",
    "\n",
    "            pm.DirichletMultinomial(\n",
    "                \"N_approve\",\n",
    "                a=concentration_polls * noisy_popularity,\n",
    "                n=data_containers[\"observed_N\"],\n",
    "                observed=data_containers[\"observed_polls\"],\n",
    "                dims=(\"observations\", \"parties_complete\"),\n",
    "            )\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            #                    ELECTION RESULTS\n",
    "            #\n",
    "            # In this section we use the variables defined before to model the\n",
    "            # political families' latent popularity and how it translates into\n",
    "            # results the day of the election.\n",
    "            #\n",
    "            # Results from previous elections enter the model here; poll\n",
    "            # results enter indirectly via the latent variable and the above\n",
    "            # regression.\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            latent_mu_t0 = (\n",
    "                party_baseline\n",
    "                + election_party_baseline\n",
    "                + party_time_effect[0]\n",
    "                + election_party_time_effect[0].T\n",
    "                + aet.dot(\n",
    "                    data_containers[\"election_unemp\"][:, None],\n",
    "                    unemployment_effect[None, :],\n",
    "                )\n",
    "            )\n",
    "            latent_mu_t0 = latent_mu_t0 + non_competing_parties[\"results\"]\n",
    "\n",
    "            latent_pop_t0 = pm.Deterministic(\n",
    "                \"latent_pop_t0\",\n",
    "                aet.nnet.softmax(latent_mu_t0),\n",
    "                dims=(\"elections\", \"parties_complete\"),\n",
    "            )\n",
    "\n",
    "            # The concentration parameter of a Dirichlet-Multinomial distribution\n",
    "            # can be interpreted as the effective number of trials.\n",
    "            #\n",
    "            # The mean (1000) is thus taken to be roughly the sample size of\n",
    "            # polls, and the standard deviation accounts for the variation in\n",
    "            # sample size.\n",
    "            concentration_results = pm.InverseGamma(\n",
    "                \"concentration_results\", mu=1000, sigma=200\n",
    "            )\n",
    "            pm.DirichletMultinomial(\n",
    "                \"R\",\n",
    "                a=concentration_results * latent_pop_t0[:-1],\n",
    "                n=data_containers[\"results_N\"],\n",
    "                observed=data_containers[\"observed_results\"],\n",
    "                dims=(\"elections_observed\", \"parties_complete\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _build_coords(self, polls: pd.DataFrame = None):\n",
    "        data = polls if polls is not None else self.polls_train\n",
    "\n",
    "        COORDS = {\n",
    "            \"observations\": data.index,\n",
    "            \"parties_complete\": self.political_families,\n",
    "        }\n",
    "        pollster_id, COORDS[\"pollsters\"] = data[\"sondage\"].factorize(sort=True)\n",
    "        countdown_id, COORDS[\"countdown\"] = data[\"countdown\"].values, np.arange(\n",
    "            data[\"countdown\"].max() + 1\n",
    "        )\n",
    "        election_id, COORDS[\"elections\"] = data[\"dateelection\"].factorize()\n",
    "        COORDS[\"elections_observed\"] = COORDS[\"elections\"][:-1]\n",
    "\n",
    "        return pollster_id, countdown_id, election_id, COORDS\n",
    "\n",
    "    def _build_data_containers(\n",
    "        self,\n",
    "        polls: pd.DataFrame = None,\n",
    "        campaign_predictors: pd.DataFrame = None,\n",
    "    ) -> Tuple[Dict[str, pm.Data], Dict[str, np.ndarray]]:\n",
    "\n",
    "        if polls is None:\n",
    "            polls = self.polls_train\n",
    "        if campaign_predictors is None:\n",
    "            campaign_predictors = self.campaign_preds\n",
    "\n",
    "        is_here = polls[self.political_families].astype(bool).astype(int)\n",
    "        non_competing_parties = {\n",
    "            \"polls_multiplicative\": is_here.values,\n",
    "            \"polls_additive\": is_here.replace(to_replace=0, value=-10)\n",
    "            .replace(to_replace=1, value=0)\n",
    "            .values,\n",
    "            \"results\": self.results_mult[self.political_families]\n",
    "            .astype(bool)\n",
    "            .astype(int)\n",
    "            .replace(to_replace=0, value=-10)\n",
    "            .replace(to_replace=1, value=0)\n",
    "            .values,\n",
    "        }\n",
    "\n",
    "        data_containers = dict(\n",
    "            election_idx=pm.Data(\"election_idx\", self.election_id, dims=\"observations\"),\n",
    "            pollster_idx=pm.Data(\"pollster_idx\", self.pollster_id, dims=\"observations\"),\n",
    "            countdown_idx=pm.Data(\n",
    "                \"countdown_idx\", self.countdown_id, dims=\"observations\"\n",
    "            ),\n",
    "            stdz_unemp=pm.Data(\n",
    "                \"stdz_unemp\",\n",
    "                campaign_predictors[\"unemployment\"].to_numpy(),\n",
    "                dims=\"observations\",\n",
    "            ),\n",
    "            election_unemp=pm.Data(\n",
    "                \"election_unemp\",\n",
    "                self.results_preds[\"unemployment\"].to_numpy(),\n",
    "                dims=\"elections\",\n",
    "            ),\n",
    "            observed_N=pm.Data(\n",
    "                \"observed_N\",\n",
    "                polls[\"samplesize\"].to_numpy(),\n",
    "                dims=\"observations\",\n",
    "            ),\n",
    "            observed_polls=pm.Data(\n",
    "                \"observed_polls\",\n",
    "                polls[self.political_families].to_numpy(),\n",
    "                dims=(\"observations\", \"parties_complete\"),\n",
    "            ),\n",
    "            results_N=pm.Data(\n",
    "                \"results_N\",\n",
    "                self.results_oos[\"samplesize\"].to_numpy(),\n",
    "                dims=\"elections_observed\",\n",
    "            ),\n",
    "            observed_results=pm.Data(\n",
    "                \"observed_results\",\n",
    "                self.results_oos[self.political_families].to_numpy(),\n",
    "                dims=(\"elections_observed\", \"parties_complete\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return data_containers, non_competing_parties\n",
    "\n",
    "    def sample_all(\n",
    "        self, *, model: pm.Model = None, var_names: List[str], **sampler_kwargs\n",
    "    ) -> arviz.InferenceData:\n",
    "        \"\"\"\n",
    "        Sample the model and return the trace.\n",
    "\n",
    "        TODO: Add 3 distinct functions to sample from the prior predictive,\n",
    "        posterior and posterior predictive distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : optional\n",
    "            A model previously created using `self.build_model()`.\n",
    "            Build a new model if None (default)\n",
    "        var_names: List[str]\n",
    "            Variables names passed to `pm.fast_sample_posterior_predictive`\n",
    "        **sampler_kwargs : dict\n",
    "            Additional arguments to `pm.sample`\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = self.build_model()\n",
    "\n",
    "        with model:\n",
    "            prior_checks = pm.sample_prior_predictive()\n",
    "            trace = pm.sample(return_inferencedata=False, **sampler_kwargs)\n",
    "            post_checks = pm.fast_sample_posterior_predictive(\n",
    "                trace, var_names=var_names\n",
    "            )\n",
    "\n",
    "        return arviz.from_pymc3(\n",
    "            trace=trace,\n",
    "            prior=prior_checks,\n",
    "            posterior_predictive=post_checks,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def forecast_election(self, idata: arviz.InferenceData) -> arviz.InferenceData:\n",
    "        \"\"\"\n",
    "        Generate out-of-sample predictions for ``election_to_predict`` specified in ``__init__``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idata: arviz.InferenceData\n",
    "            Posterior trace generated by ``self.sample_all`` on the training dataset.\n",
    "            The dataset used for predictions is generated automatically: one observation for each\n",
    "            of the days in ``self.coords[\"countdown\"]``. The corresponding values of predictors are\n",
    "            handled automatically.\n",
    "        \"\"\"\n",
    "        new_dates, oos_data = self._generate_oos_data(idata)\n",
    "        oos_data = self._join_with_continuous_predictors(oos_data)\n",
    "        forecast_data_index = pd.DataFrame(\n",
    "            data=0,  # just a placeholder\n",
    "            index=pd.MultiIndex.from_frame(oos_data),\n",
    "            columns=self.political_families,\n",
    "        )\n",
    "        forecast_data = forecast_data_index.reset_index()\n",
    "\n",
    "        PREDICTION_COORDS = {\"observations\": new_dates}\n",
    "        PREDICTION_DIMS = {\n",
    "            \"latent_popularity\": [\"observations\", \"parties_complete\"],\n",
    "            \"noisy_popularity\": [\"observations\", \"parties_complete\"],\n",
    "            \"N_approve\": [\"observations\", \"parties_complete\"],\n",
    "        }\n",
    "\n",
    "        forecast_model = self.build_model(\n",
    "            polls=forecast_data,\n",
    "            continuous_predictors=forecast_data,\n",
    "        )\n",
    "        with forecast_model:\n",
    "            ppc = pm.fast_sample_posterior_predictive(\n",
    "                idata,\n",
    "                var_names=[\n",
    "                    \"party_baseline\",\n",
    "                    \"latent_popularity\",\n",
    "                    \"noisy_popularity\",\n",
    "                    \"N_approve\",\n",
    "                    \"latent_pop_t0\",\n",
    "                    \"R\",\n",
    "                ],\n",
    "            )\n",
    "            ppc = arviz.from_pymc3_predictions(\n",
    "                ppc,\n",
    "                idata_orig=idata,\n",
    "                inplace=False,\n",
    "                coords=PREDICTION_COORDS,\n",
    "                dims=PREDICTION_DIMS,\n",
    "            )\n",
    "\n",
    "        return ppc\n",
    "\n",
    "    def _generate_oos_data(\n",
    "        self, idata: arviz.InferenceData\n",
    "    ) -> Tuple[pd.Index, pd.DataFrame]:\n",
    "\n",
    "        countdown = idata.posterior[\"countdown\"]\n",
    "        elections = idata.posterior[\"elections\"]\n",
    "\n",
    "        estimated_days = np.tile(countdown[::-1], reps=len(elections))\n",
    "        N_estimated_days = len(estimated_days)\n",
    "\n",
    "        new_dates = [\n",
    "            pd.date_range(\n",
    "                periods=max(countdown.data) + 1,\n",
    "                end=date,\n",
    "                freq=\"D\",\n",
    "            ).to_series()\n",
    "            for date in elections.data\n",
    "        ]\n",
    "        new_dates = pd.concat(new_dates).index\n",
    "\n",
    "        oos_data = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"countdown\": estimated_days,\n",
    "                \"dateelection\": np.repeat(\n",
    "                    self.unique_elections, repeats=len(countdown)\n",
    "                ),\n",
    "                \"sondage\": np.random.choice(\n",
    "                    self.unique_pollsters, size=N_estimated_days\n",
    "                ),\n",
    "                \"samplesize\": np.random.choice(\n",
    "                    self.results_oos[\"samplesize\"].values, size=N_estimated_days\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        oos_data[\"date\"] = new_dates\n",
    "\n",
    "        return new_dates, oos_data.set_index(\"date\")\n",
    "\n",
    "    def _join_with_continuous_predictors(self, oos_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        oos_data[\"quarter\"] = oos_data.index.to_period(\"Q\")\n",
    "        oos_data[\"month\"] = oos_data.index.to_period(\"M\")\n",
    "\n",
    "        oos_data = oos_data.join(self.unemployment_data, on=\"quarter\")\n",
    "        # check no missing values\n",
    "        np.testing.assert_allclose(0, oos_data.isna().any().mean())\n",
    "\n",
    "        # stdz predictors based on observed values\n",
    "        oos_data[\"unemployment\"] = (\n",
    "            oos_data[\"unemployment\"] - self.continuous_predictors[\"unemployment\"].mean()\n",
    "        ) / self.continuous_predictors[\"unemployment\"].std()\n",
    "\n",
    "        return oos_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
